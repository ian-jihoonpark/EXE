# EXE
EXE: Explaining teXt Explanation by Aligning Multi-modal Streams

# Task
<p align="center">
  <img src="https://github.com/ian-jihoonpark/EXE/assets/77654517/a960312d-d94d-410b-891e-9e5322ec508c" width="400" height="400">
</p>

# Model Architecture
Multimodal information from a single stream is better than single-stream
<p align="center">
  <img src="https://github.com/ian-jihoonpark/EXE/assets/77654517/972fd83f-8eac-4eba-ad8c-fd5aea512547" width="400" height="400">
  <img src="https://github.com/ian-jihoonpark/EXE/assets/77654517/6d2eb4de-03cd-49c8-ad2a-40a886e5cb9a" width="400" height="400">
</p>

# Experiments
Multi-stream cannot see the visual feature. \
However, single-stream watch the visual feature when it generates the answer and explanation
<p align="center">
  <img src="https://github.com/ian-jihoonpark/EXE/assets/77654517/c4507f6f-d79f-4930-b01e-0e640dd4c5d1" width="400" height="400">
  <img src="https://github.com/ian-jihoonpark/EXE/assets/77654517/912dae93-5f11-4127-a3f0-af4ad7604771" width="400" height="400">
</p>
